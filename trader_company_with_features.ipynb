{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1jemM_tgOJiCdj_4STptxZOC0pQYlTk3b",
      "authorship_tag": "ABX9TyMq1Xj7n3FDCQTpN5LyPVws",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/niwatoro/trader-company/blob/main/trader_company_with_features.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVoAyaxJYqWp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "from tqdm.contrib import tenumerate\n",
        "import random\n",
        "from datetime import datetime\n",
        "from dataclasses import dataclass, field\n",
        "from numpy.typing import NDArray\n",
        "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import TimeSeriesSplit, GridSearchCV\n",
        "from sklearn.pipeline import make_pipeline, Pipeline\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from IPython.display import display"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_oil = pd.read_csv(\"drive/MyDrive/DIESEL.CMDUSD_Candlestick_1_Hour_BID_26.12.2017-02.08.2025.csv\")\n",
        "df_oil[\"Gmt time\"] = pd.to_datetime(df_oil[\"Gmt time\"], format=\"%d.%m.%Y %H:%M:%S.%f\")\n",
        "df_oil[\"ma_20\"] = df_oil[\"Close\"].rolling(20).mean()\n",
        "df_oil[\"ma_50\"] = df_oil[\"Close\"].rolling(50).mean()\n",
        "df_oil.set_index(\"Gmt time\", inplace=True)\n",
        "df_oil[\"Close\"].plot(grid=True)"
      ],
      "metadata": {
        "id": "Bg8gm2PyDyDf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_vol = pd.read_csv(\"drive/MyDrive/VOL.IDXUSD_Candlestick_1_Hour_BID_05.10.2022-02.08.2025.csv\")\n",
        "df_vol[\"Gmt time\"] = pd.to_datetime(df_vol[\"Gmt time\"], format=\"%d.%m.%Y %H:%M:%S.%f\")\n",
        "df_vol[\"ma_20\"] = df_vol[\"Close\"].rolling(20).mean()\n",
        "df_vol[\"ma_50\"] = df_vol[\"Close\"].rolling(50).mean()\n",
        "df_vol.set_index(\"Gmt time\", inplace=True)\n",
        "df_vol[\"Close\"].plot(grid=True)"
      ],
      "metadata": {
        "id": "2futI16HEnQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_ninja = pd.read_csv(\"drive/MyDrive/USDJPY_Candlestick_1_Hour_BID_05.05.2003-02.08.2025.csv\").iloc[:-30]\n",
        "df_ninja[\"Gmt time\"] = pd.to_datetime(df_ninja[\"Gmt time\"], format=\"%d.%m.%Y %H:%M:%S.%f\")\n",
        "df_ninja.set_index(\"Gmt time\", inplace=True)\n",
        "df_ninja[\"ma_20\"] = df_ninja[\"Close\"].rolling(20).mean()\n",
        "df_ninja[\"ma_50\"] = df_ninja[\"Close\"].rolling(50).mean()\n",
        "df_ninja[\"return\"] = np.log(df_ninja[\"Close\"] / df_ninja[\"Close\"].shift(1))\n",
        "df_ninja[\"Close\"].plot(grid=True)"
      ],
      "metadata": {
        "id": "k1Yzgn8njYSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.concat([\n",
        "    df_ninja[\"return\"],\n",
        "    df_vol[[\"Close\", \"ma_20\", \"ma_50\"]].shift(1),\n",
        "    df_oil[[\"Close\", \"ma_20\", \"ma_50\"]].shift(1),\n",
        "], axis=1).dropna()\n",
        "df.columns = [\"ret\", \"vol\", \"vol_ma_20\", \"vol_ma_50\", \"oil\", \"oil_ma_20\", \"oil_ma_50\", ]\n",
        "df"
      ],
      "metadata": {
        "id": "ErQpDkNxEws0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def op_add(x, y): return x + y\n",
        "def op_sub(x, y): return x - y\n",
        "def op_mul(x, y): return x * y\n",
        "def op_x(x, y): return x\n",
        "def op_y(x, y): return y\n",
        "def op_max(x, y): return np.maximum(x, y)\n",
        "def op_min(x, y): return np.minimum(x, y)\n",
        "def op_gt(x, y): return np.sign(x - y)\n",
        "def op_lt(x, y): return np.sign(y - x)\n",
        "def op_corr(x, y):\n",
        "  if x.size != y.size or x.size < 2:\n",
        "    return .0\n",
        "  if not np.isfinite(x).all() or not np.isfinite(y).all():\n",
        "    return .0\n",
        "  sx = np.std(x)\n",
        "  sy = np.std(y)\n",
        "  if sx == 0 or sy == 0:\n",
        "    return .0\n",
        "  return float(np.corrcoef(x, y)[0, 1])\n",
        "\n",
        "OPERATORS = {\n",
        "    \"add\": op_add,\n",
        "    \"sub\": op_sub,\n",
        "    \"mul\": op_mul,\n",
        "    \"x\": op_x,\n",
        "    \"y\": op_y,\n",
        "    \"max\": op_max,\n",
        "    \"min\": op_min,\n",
        "    \"gt\": op_gt,\n",
        "    \"lt\": op_lt,\n",
        "    \"corr\": op_corr,\n",
        "}"
      ],
      "metadata": {
        "id": "Q5NHc_sDdkH9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def act_identity(x): return x\n",
        "def act_tanh(x): return np.tanh(x)\n",
        "def act_exp(x): return np.exp(np.clip(x, -10, 10))\n",
        "def act_sign(x): return np.sign(x)\n",
        "def act_relu(x): return np.maximum(x, .0)\n",
        "def act_sinh(x): return np.sinh(x)\n",
        "\n",
        "ACTIVATIONS = {\n",
        "    \"identity\": act_identity,\n",
        "    \"tanh\": act_tanh,\n",
        "    \"exp\": act_exp,\n",
        "    \"sign\": act_sign,\n",
        "    # \"sinh\": act_sinh,\n",
        "    \"relu\": act_relu,\n",
        "}"
      ],
      "metadata": {
        "id": "tvwZU2p9lNLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class Term:\n",
        "  op: str\n",
        "  act: str\n",
        "  var_i: int\n",
        "  var_j: int\n",
        "  delay_i: int\n",
        "  delay_j: int\n",
        "  weight: float"
      ],
      "metadata": {
        "id": "UE73A6npFd9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class Trader:\n",
        "  M: int\n",
        "  terms: list[Term]\n",
        "\n",
        "  @staticmethod\n",
        "  def sample_random(\n",
        "      num_vars: int,\n",
        "      max_delay: int,\n",
        "      rng: random.Random,\n",
        "      M_range: tuple[int, int]=(1, 10),\n",
        "  ) -> \"Trader\":\n",
        "    M = rng.randint(M_range[0], M_range[1])\n",
        "    terms: list[Term] = []\n",
        "    for _ in range(M):\n",
        "      op = rng.choice(list(OPERATORS.keys()))\n",
        "      act = rng.choice(list(ACTIVATIONS.keys()))\n",
        "      var_i = rng.randrange(num_vars)\n",
        "      var_j = rng.randrange(num_vars)\n",
        "      delay_i = rng.randint(0, max_delay)\n",
        "      delay_j = rng.randint(0, max_delay)\n",
        "      weight = rng.uniform(-1., 1.) / math.sqrt(M)\n",
        "      terms.append(Term(op, act, var_i, var_j, delay_i, delay_j, weight))\n",
        "    return Trader(M=M, terms=terms)\n",
        "\n",
        "  @staticmethod\n",
        "  def fit_weights_l2(\n",
        "      X: NDArray,\n",
        "      y: NDArray,\n",
        "      alpha: float=1e-12,\n",
        "      sample_weight=None,\n",
        "  ) -> NDArray:\n",
        "    X = np.asarray(X, dtype=float)\n",
        "    y = np.asarray(y, dtype=float)\n",
        "    col_std = X.std(axis=0)\n",
        "    keep = col_std > alpha\n",
        "    if keep.sum() == 0:\n",
        "      return np.zeros(X.shape[1], dtype=float)\n",
        "\n",
        "    model = Ridge(alpha=alpha, fit_intercept=False, copy_X=True, random_state=0)\n",
        "    model.fit(X[:, keep], y, sample_weight=sample_weight)\n",
        "\n",
        "    coef = np.zeros(X.shape[1], dtype=float)\n",
        "    coef[keep] = model.coef_\n",
        "    return coef\n",
        "\n",
        "  def _raw_feature_term_value(self, X: NDArray, t: int, term: Term, l: int, w: int) -> float:\n",
        "    di = term.delay_i\n",
        "    dj = term.delay_j\n",
        "    ti = t - l - di\n",
        "    tj = t - l - dj\n",
        "\n",
        "    if term.op == \"corr\":\n",
        "      if ti - (w - 1) < 0 or tj - (w - 1) < 0:\n",
        "        return 0.0\n",
        "\n",
        "      seg_i = X[ti - (w - 1): ti + 1, term.var_i]\n",
        "      seg_j = X[tj - (w - 1): tj + 1, term.var_j]\n",
        "      z = op_corr(seg_i, seg_j)\n",
        "    else:\n",
        "      if ti < 0 or tj < 0:\n",
        "        return .0\n",
        "\n",
        "      x = X[ti, term.var_i]\n",
        "      y = X[tj, term.var_j]\n",
        "      z = OPERATORS[term.op](x, y)\n",
        "\n",
        "    z = ACTIVATIONS[term.act](z)\n",
        "    return float(z)\n",
        "\n",
        "  def _features_at_t(self, X: NDArray, t: int, l: int, w: int) -> NDArray:\n",
        "    return np.asarray([\n",
        "        float(term.weight * self._raw_feature_term_value(X, t, term, l, w))\n",
        "        for term in self.terms\n",
        "    ], dtype=float)\n",
        "\n",
        "  def predict_at_t(self, X: NDArray, t: int, l: int, w: int) -> float:\n",
        "    vals = self._features_at_t(X, t, l, w)\n",
        "    return float(np.nansum(vals))\n",
        "\n",
        "  def fit_weights_least_squares(\n",
        "      self,\n",
        "      X: np.ndarray,\n",
        "      y: np.ndarray,\n",
        "      t_index: list[int],\n",
        "      l: int,\n",
        "      w: int\n",
        "  ) -> None:\n",
        "    Phi: list[list[float]] = []\n",
        "    yv: list[float] = []\n",
        "\n",
        "    for t in t_index:\n",
        "      tv: list[float] = []\n",
        "      valid: bool = True\n",
        "\n",
        "      for term in self.terms:\n",
        "        di = term.delay_i\n",
        "        dj = term.delay_j\n",
        "        ti = t - l - di\n",
        "        tj = t - l - dj\n",
        "\n",
        "        if term.op == \"corr\":\n",
        "          if ti - (w - 1) < 0 or tj - (w - 1) < 0:\n",
        "            valid = False\n",
        "            break\n",
        "        else:\n",
        "          if ti < 0 or tj < 0:\n",
        "            valid = False\n",
        "            break\n",
        "        tv.append(self._raw_feature_term_value(X, t, term, l, w))\n",
        "\n",
        "      if valid:\n",
        "        Phi.append(tv)\n",
        "        yv.append(y[t + 1])\n",
        "\n",
        "    if len(Phi) >= self.M:\n",
        "      Phi = np.asarray(Phi, dtype=float)\n",
        "      yv = np.asarray(yv, dtype=float)\n",
        "      coef = self.fit_weights_l2(Phi, yv)\n",
        "      for k, term in enumerate(self.terms):\n",
        "        term.weight = float(coef[k])\n",
        "\n",
        "  @staticmethod\n",
        "  def _positions_hard_threshold(pred: NDArray, tau: float) -> NDArray:\n",
        "    pred = np.asarray(pred, dtype=float)\n",
        "    return np.where(np.abs(pred) > tau, np.sign(pred), .0)\n",
        "\n",
        "  def cumulative_return(self, X: NDArray, target_returns: NDArray, t_index: list[int], l: int, w: int) -> float:\n",
        "    pnl = .0\n",
        "    tau = .75 * np.nanstd(target_returns[t_index])\n",
        "    for t in t_index:\n",
        "      pred = self.predict_at_t(X, t, l, w)\n",
        "      pnl += self._positions_hard_threshold(pred, tau) * target_returns[t + 1]\n",
        "    return float(pnl)"
      ],
      "metadata": {
        "id": "cjoRZHMNnlr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = make_pipeline(\n",
        "    StandardScaler(with_mean=True, with_std=True),\n",
        "    RidgeCV(alphas=np.logspace(-4, 2, 20), cv=TimeSeriesSplit(n_splits=5)),\n",
        ")\n",
        "\n",
        "@dataclass\n",
        "class Company:\n",
        "  target_var: int\n",
        "  w: int=10\n",
        "  l: int=1\n",
        "  num_traders: int=128\n",
        "  max_delay: int=10\n",
        "  Q: float=.5\n",
        "  rng: random.Random=field(default_factory=random.Random)\n",
        "  traders: list[Trader]=field(default_factory=list)\n",
        "  aggregator: Pipeline | None=None\n",
        "  diversity_lambda: float=.2\n",
        "\n",
        "  def initialize_traders(self, num_vars: int, M_range=(1, 10)) -> None:\n",
        "    self.traders = [\n",
        "        Trader.sample_random(\n",
        "            num_vars=num_vars,\n",
        "            max_delay=self.max_delay,\n",
        "            rng=self.rng,\n",
        "            M_range=M_range\n",
        "        ) for _ in range(self.num_traders)\n",
        "    ]\n",
        "\n",
        "  def predict_one(self, X: NDArray, t: int) -> float:\n",
        "    feats = np.array([tr.predict_at_t(X, t, self.l, self.w) for tr in self.traders], dtype=float)\n",
        "    if self.aggregator is None:\n",
        "      return float(np.nansum(feats))\n",
        "    return float(self.aggregator.predict(feats.reshape(1, -1))[0])\n",
        "\n",
        "  def _fit_gmms_from_elite(self, elite: list[Trader]) -> dict:\n",
        "    delays_i = []\n",
        "    delays_j = []\n",
        "    weights = []\n",
        "    ops = []\n",
        "    acts = []\n",
        "    vis = []\n",
        "    vjs = []\n",
        "    Ms = []\n",
        "\n",
        "    for tr in elite:\n",
        "      Ms.append(tr.M)\n",
        "      for term in tr.terms:\n",
        "        delays_i.append(term.delay_i)\n",
        "        delays_j.append(term.delay_j)\n",
        "        weights.append(term.weight)\n",
        "        ops.append(term.op)\n",
        "        acts.append(term.act)\n",
        "        vis.append(term.var_i)\n",
        "        vjs.append(term.var_j)\n",
        "\n",
        "    params = {}\n",
        "\n",
        "    def fit_gmm_1d(samples: list, n_components=2) -> GaussianMixture:\n",
        "      samples = np.asarray(samples, dtype=float).reshape(-1, 1)\n",
        "      if samples.shape[0] < n_components:\n",
        "        return None\n",
        "      if np.std(samples) < 1e-12:\n",
        "        return None\n",
        "\n",
        "      try:\n",
        "        gmm = GaussianMixture(\n",
        "            n_components=min(n_components, max(1, samples.shape[0])),\n",
        "            covariance_type=\"full\",\n",
        "            reg_covar=1e-3,\n",
        "            random_state=0,\n",
        "        )\n",
        "        gmm.fit(samples)\n",
        "        return gmm\n",
        "      except Exception as e:\n",
        "        print(e)\n",
        "        return None\n",
        "\n",
        "    params[\"gmm_delay_i\"] = fit_gmm_1d(delays_i)\n",
        "    params[\"gmm_delay_j\"] = fit_gmm_1d(delays_j)\n",
        "    params[\"gmm_weight\"] = fit_gmm_1d(weights, n_components=3)\n",
        "\n",
        "    def freq_dist(values: list) -> tuple[list, list]:\n",
        "      values = list(values)\n",
        "      uniq, counts = np.unique(values, return_counts=True)\n",
        "      probs = counts / counts.sum()\n",
        "      return list(uniq), list(probs)\n",
        "\n",
        "    params[\"ops\"] = freq_dist(ops) if ops else (\n",
        "        list(OPERATORS.keys()), [1 / len(OPERATORS)] * len(OPERATORS)\n",
        "    )\n",
        "    params[\"acts\"] = freq_dist(acts) if acts else (\n",
        "        list(ACTIVATIONS.keys()), [1 / len(ACTIVATIONS)] * len(ACTIVATIONS)\n",
        "    )\n",
        "    params[\"vis\"] = freq_dist(vis) if vis else ([0], [1.])\n",
        "    params[\"vjs\"] = freq_dist(vjs) if vjs else ([0], [1.])\n",
        "    params[\"Ms\"] = freq_dist(Ms) if Ms else ([3], [1.])\n",
        "    return params\n",
        "\n",
        "  def _sample_from_gmm_or_empirical(\n",
        "      self,\n",
        "      gmm: GaussianMixture,\n",
        "      samples: list[int],\n",
        "      clamp: tuple[int, int]=None,\n",
        "      is_int: bool=False\n",
        "  ) -> float | int:\n",
        "    if gmm is not None:\n",
        "      val = float(gmm.sample()[0].ravel()[0])\n",
        "    else:\n",
        "      if not samples:\n",
        "        val = .0\n",
        "      else:\n",
        "        mu = float(np.mean(samples))\n",
        "        sigma = float(np.std(samples) if np.std(samples) > 0 else 1.)\n",
        "        val = float(self.rng.normalvariate(mu, sigma * .25))\n",
        "    if clamp is not None:\n",
        "      val = max(clamp[0], min(clamp[1], val))\n",
        "    if is_int:\n",
        "      val = int(round(val))\n",
        "    return val\n",
        "\n",
        "  def _generate_new_trader_from_gmm(self, num_vars: int, params: dict) -> Trader:\n",
        "    ops_vals, ops_p = params[\"ops\"]\n",
        "    acts_vals, acts_p = params[\"acts\"]\n",
        "    vis_vals, vis_p = params[\"vis\"]\n",
        "    vjs_vals, vjs_p = params[\"vjs\"]\n",
        "    Ms_vals, Ms_p = params[\"Ms\"]\n",
        "\n",
        "    M = int(self.rng.choices(Ms_vals, weights=Ms_p, k=1)[0])\n",
        "    M = max(1, min(10, M))\n",
        "\n",
        "    terms: list[Term] = []\n",
        "    for _ in range(M):\n",
        "      op = self.rng.choices(ops_vals, weights=ops_p, k=1)[0]\n",
        "      act = self.rng.choices(acts_vals, weights=acts_p, k=1)[0]\n",
        "      vi = int(self.rng.choices(vis_vals, weights=vis_p, k=1)[0]) % num_vars\n",
        "      vj = int(self.rng.choices(vjs_vals, weights=vjs_p, k=1)[0]) % num_vars\n",
        "\n",
        "      di = self._sample_from_gmm_or_empirical(\n",
        "          params[\"gmm_delay_i\"],\n",
        "          [t.delay_i for tr in self.traders for t in tr.terms],\n",
        "          clamp=None,\n",
        "          is_int=True,\n",
        "      )\n",
        "      dj = self._sample_from_gmm_or_empirical(\n",
        "          params[\"gmm_delay_j\"],\n",
        "          [t.delay_j for tr in self.traders for t in tr.terms],\n",
        "          clamp=None,\n",
        "          is_int=True,\n",
        "      )\n",
        "      w = self._sample_from_gmm_or_empirical(\n",
        "          params[\"gmm_weight\"],\n",
        "          [t.weight for tr in self.traders for t in tr.terms],\n",
        "          clamp=None,\n",
        "          is_int=False,\n",
        "      )\n",
        "      terms.append(Term(op=str(op), act=str(act), var_i=vi, var_j=vj, delay_i=di, delay_j=dj, weight=float(w)))\n",
        "    return Trader(M=len(terms), terms=terms)\n",
        "\n",
        "  def _find_bad_traders(\n",
        "      self,\n",
        "      X: NDArray,\n",
        "      target_returns: NDArray,\n",
        "      t_index: list[int]\n",
        "  ) -> tuple[list[int], list[int]]:\n",
        "    scores = np.array([\n",
        "        tr.cumulative_return(X, target_returns, t_index, self.l, self.w)\n",
        "        for tr in self.traders\n",
        "    ], dtype=float)\n",
        "    thresh = np.percentile(scores, self.Q * 100.)\n",
        "    bad_idx = [i for i, s in enumerate(scores) if s <= thresh]\n",
        "    return scores, bad_idx\n",
        "\n",
        "  def _trader_outputs_matrix(self, X: NDArray, t_index: list[int], standardize: bool=True) -> NDArray:\n",
        "    Z = np.array([[tr.predict_at_t(X, t, self.l, self.w) for tr in self.traders] for t in t_index], dtype=float)\n",
        "    if standardize:\n",
        "      Z = (Z - Z.mean(axis=0, keepdims=True)) / (Z.std(axis=0, keepdims=True) + 1e-9)\n",
        "    return Z\n",
        "\n",
        "  def _select_elite_diverse_greedy(\n",
        "      self,\n",
        "      X: NDArray,\n",
        "      t_index: list[int],\n",
        "      scores: NDArray,\n",
        "      k: int,\n",
        "      lam: float\n",
        "  ) -> NDArray:\n",
        "    Z = self._trader_outputs_matrix(X, t_index, standardize=True)\n",
        "    N = Z.shape[1]\n",
        "    C = (Z.T @ Z) / (Z.shape[0] + 1e-9)\n",
        "    C = np.clip(C, -1., 1.)\n",
        "    scores = np.asarray(scores, dtype=float)\n",
        "\n",
        "    selected = [int(np.nanargmax(scores))]\n",
        "    remaining = set(range(N)) - set(selected)\n",
        "    while len(selected) < min(k, N) and remaining:\n",
        "      sel = np.array(selected, dtype=int)\n",
        "      maxcorr = np.max(np.abs(C[:, sel]), axis=1)\n",
        "      cand = np.array(list(remaining), dtype=int)\n",
        "      adj = scores[cand] - lam * maxcorr[cand]\n",
        "      nxt = int(cand[np.nanargmax(adj)])\n",
        "      selected.append(nxt)\n",
        "      remaining.remove(nxt)\n",
        "    return np.array(selected[:k], dtype=int)\n",
        "\n",
        "  def train_epoch(self, X: NDArray, target_returns: NDArray, t_index: list[int]) -> None:\n",
        "    scores, bad_idx = self._find_bad_traders(X, target_returns, t_index)\n",
        "\n",
        "    for i in bad_idx:\n",
        "      self.traders[i].fit_weights_least_squares(X, target_returns, t_index, self.l, self.w)\n",
        "\n",
        "    scores, bad_idx = self._find_bad_traders(X, target_returns, t_index)\n",
        "\n",
        "    k = max(1, int(round(self.Q * len(self.traders))))\n",
        "    elite_idx = self._select_elite_diverse_greedy(X, t_index, scores, k, lam=self.diversity_lambda)\n",
        "    elite = [self.traders[i] for i in elite_idx]\n",
        "    params = self._fit_gmms_from_elite(elite)\n",
        "\n",
        "    new_traders: list[Trader] = [\n",
        "        self._generate_new_trader_from_gmm(num_vars=X.shape[1], params=params)\n",
        "        for _ in bad_idx\n",
        "    ]\n",
        "\n",
        "    for idx, nt in zip(bad_idx, new_traders):\n",
        "      self.traders[idx] = nt\n",
        "\n",
        "  def fit_aggregator(self, X: NDArray, target_returns: NDArray, t_index: list[int]) -> None:\n",
        "    Z = np.array([[tr.predict_at_t(X, t, self.l, self.w) for tr in self.traders] for t in t_index], dtype=float)\n",
        "    y = np.array([target_returns[t + 1] for t in t_index], dtype=float)\n",
        "    self.aggregator = pipe.fit(Z, y)\n",
        "\n",
        "  def accuracy(self, preds: NDArray, actual: NDArray) -> float:\n",
        "    return float((np.sign(preds) == np.sign(actual)).mean())\n",
        "\n",
        "  def canonical_trade_returns(self, preds: NDArray, actual: NDArray) -> NDArray:\n",
        "    simple = np.expm1(actual)\n",
        "    return np.sign(preds) * simple\n",
        "\n",
        "  def evaluate(self, preds: NDArray, actual: NDArray) -> dict[str, float]:\n",
        "    trade_rets = self.canonical_trade_returns(preds, actual)\n",
        "    cum = np.cumprod(1. + trade_rets)\n",
        "    AR = (cum[-1] ** (24 * 365 / len(cum))) - 1.\n",
        "    SR = np.mean(trade_rets) / (np.std(trade_rets) + 1e-9) * np.sqrt(24 * 365)\n",
        "    roll_max = np.maximum.accumulate(cum)\n",
        "    dd = (cum / roll_max) - 1.\n",
        "    CR = (np.mean(trade_rets) * 24 * 365) / (1e-9 + np.abs(np.min(dd)))\n",
        "    return {\n",
        "        \"ACC\": self.accuracy(preds, actual),\n",
        "        \"AR_%\": 100. * AR,\n",
        "        \"SR\": SR,\n",
        "        \"CR\": CR,\n",
        "        \"cum_end\": cum[-1],\n",
        "    }"
      ],
      "metadata": {
        "id": "bhKE2k4MGpsg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_equity_curve(time_series: NDArray, trade_rets: NDArray) -> None:\n",
        "  cum = np.cumprod(1. + trade_rets)\n",
        "\n",
        "  plt.plot(time_series, cum)\n",
        "  plt.xticks(rotation=90)\n",
        "  plt.grid()\n",
        "  plt.show()\n",
        "\n",
        "def plot_aggregator_coeffs(company: Company, top_k: int=20, title: str=\"Aggregator Coefficients\") -> None:\n",
        "  coefs = getattr(company.aggregator.steps[-1][1], \"coef_\", None)\n",
        "  idx = np.argsort(np.abs(coefs))[-top_k:][::-1]\n",
        "  x = np.arange(len(idx))\n",
        "  labels = [str(i) for i in idx]\n",
        "  y = coefs[idx]\n",
        "\n",
        "  plt.bar(x, y)\n",
        "  plt.xticks(x, labels)\n",
        "  plt.title(title)\n",
        "  plt.show()\n",
        "\n",
        "def describe_top_traders(company: Company, top_k: int=5, var_names: list[str] | None=None):\n",
        "  coefs = getattr(company.aggregator.steps[-1][1], \"coef_\", None)\n",
        "  coefs = np.asarray(coefs, dtype=float)\n",
        "\n",
        "  order = np.argsort(np.abs(coefs))[::-1]\n",
        "  top_idx = order[:min(top_k, len(coefs))]\n",
        "\n",
        "  rows = []\n",
        "  for rank, i in enumerate(top_idx, 1):\n",
        "    tr = company.traders[i]\n",
        "    coef = float(coefs[i])\n",
        "    for m, term in enumerate(tr.terms, 1):\n",
        "      vi = var_names[term.var_i] if (\n",
        "          var_names is not None and 0 <= term.var_i < len(var_names)\n",
        "      ) else str(term.var_i)\n",
        "      vj = var_names[term.var_j] if (\n",
        "          var_names is not None and 0 <= term.var_j < len(var_names)\n",
        "      ) else str(term.var_j)\n",
        "\n",
        "      rows.append({\n",
        "        \"rank\": rank,\n",
        "        \"trader_idx\": i,\n",
        "        \"agg_coef\": coef,\n",
        "        \"M\": tr.M,\n",
        "        \"term_no\": m,\n",
        "        \"term_weight\": term.weight,\n",
        "        \"op\": term.op,\n",
        "        \"act\": term.act,\n",
        "        \"var_i\": term.var_i,\n",
        "        \"var_j\": term.var_j,\n",
        "        \"var_i_name\": vi if isinstance(vi, str) else str(vi),\n",
        "        \"var_j_name\": vj if isinstance(vj, str) else str(vj),\n",
        "        \"delay_i\": term.delay_i,\n",
        "        \"delay_j\": term.delay_j,\n",
        "      })\n",
        "\n",
        "  display(pd.DataFrame(rows))"
      ],
      "metadata": {
        "id": "mYp-Tmm4HilB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_eval(df: pd.DataFrame, test_fraction: float=0.1, train_epoch: int=1) -> None:\n",
        "  rng = random.Random(123)\n",
        "\n",
        "  X = df.values.astype(float)\n",
        "  y = df[\"ret\"].values.astype(float)\n",
        "\n",
        "  T = X.shape[0]\n",
        "  w = 10\n",
        "  l = 1\n",
        "  max_delay = 24\n",
        "  safe_start = w + l + max_delay\n",
        "  t_all = list(range(safe_start, T - 1))\n",
        "\n",
        "  split = int(len(t_all) * (1. - test_fraction))\n",
        "  train_t = t_all[:split]\n",
        "  test_t = t_all[split:]\n",
        "\n",
        "  print(f\"[{datetime.now().strftime('%Y%m%d %H:%M:%S')}] Initializing...\")\n",
        "  company = Company(target_var=0, num_traders=32, w=w, l=l, max_delay=max_delay, Q=.5, rng=rng)\n",
        "  company.initialize_traders(num_vars=X.shape[1], M_range=(1, 3))\n",
        "\n",
        "  print(f\"[{datetime.now().strftime('%Y%m%d %H:%M:%S')}] Training...\")\n",
        "  for _ in tqdm(range(train_epoch)):\n",
        "    company.train_epoch(X, y, train_t)\n",
        "\n",
        "  print(f\"[{datetime.now().strftime('%Y%m%d %H:%M:%S')}] Fitting aggregator...\")\n",
        "  company.fit_aggregator(X, y, train_t)\n",
        "\n",
        "  print(f\"[{datetime.now().strftime('%Y%m%d %H:%M:%S')}] Evaluating...\")\n",
        "  train_preds = np.array([company.predict_one(X, t) for t in train_t])\n",
        "  test_preds = np.array([company.predict_one(X, t) for t in test_t])\n",
        "  train_actual = np.array([y[t + 1] for t in train_t])\n",
        "  test_actual = np.array([y[t + 1] for t in test_t])\n",
        "\n",
        "  train_tr = company.canonical_trade_returns(train_preds, train_actual)\n",
        "  test_tr = company.canonical_trade_returns(test_preds, test_actual)\n",
        "\n",
        "  print(f\"[{datetime.now().strftime('%Y%m%d %H:%M:%S')}] Displaying results...\")\n",
        "  plot_equity_curve(df.index[train_t], train_tr)\n",
        "  plot_equity_curve(df.index[test_t], test_tr)\n",
        "  plot_aggregator_coeffs(company)\n",
        "  describe_top_traders(company, 5, df.columns)\n",
        "\n",
        "  train_metrics = company.evaluate(train_preds, train_actual)\n",
        "  test_metrics = company.evaluate(test_preds, test_actual)\n",
        "\n",
        "  print(\"[Train]\")\n",
        "  for key, val in train_metrics.items():\n",
        "    print(f\"{key}:\\t{val:.3f}\")\n",
        "  print()\n",
        "  print(\"[Test]\")\n",
        "  for key, val in test_metrics.items():\n",
        "    print(f\"{key}:\\t{val:.3f}\")"
      ],
      "metadata": {
        "id": "hx9BdwDT2Um-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_and_eval(df)"
      ],
      "metadata": {
        "id": "PGCmTeUH-PWB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def walk_forward_eval(\n",
        "    df: pd.DataFrame,\n",
        "    *,\n",
        "    initial_train_size: int=24*90,\n",
        "    retrain_every: int=24*7,\n",
        "    lookback: int | None=None,\n",
        "    epochs_per_update: int=1,\n",
        "    num_traders: int=32,\n",
        "    M_range: tuple[int, int]=(1, 3),\n",
        "    Q: float=.5,\n",
        "    seed: int=123,\n",
        "    min_fit_samples: int=60,\n",
        "    reset_on_update: bool=False,\n",
        ") -> dict[str, float]:\n",
        "  rng = random.Random(seed)\n",
        "\n",
        "  X = df.values.astype(float)\n",
        "  y = df[\"ret\"].values.astype(float)\n",
        "\n",
        "  w = 10\n",
        "  l = 1\n",
        "  max_delay = 24\n",
        "  safe_start =  w + l + max_delay\n",
        "  T = X.shape[0]\n",
        "\n",
        "  first_t = safe_start + max(1, int(initial_train_size))\n",
        "\n",
        "  company = None\n",
        "\n",
        "  preds: list[float] = []\n",
        "  actual: list[float] = []\n",
        "  times: list[pd.Timestamp] = []\n",
        "\n",
        "  def make_train_index(t_now: int) -> list[int]:\n",
        "    if lookback is None:\n",
        "      start = safe_start\n",
        "    else:\n",
        "      start = max(safe_start, t_now - int(lookback))\n",
        "    return list(range(start, t_now))\n",
        "\n",
        "  steps = list(range(first_t, T - 1))\n",
        "  last_update_step = -1e9\n",
        "\n",
        "  for step_idx, t in tenumerate(steps):\n",
        "    if (company is None) or (t - last_update_step >= retrain_every):\n",
        "      train_t = make_train_index(t)\n",
        "\n",
        "      if company is None or reset_on_update:\n",
        "        company = Company(\n",
        "            target_var=0,\n",
        "            num_traders=num_traders,\n",
        "            w=w,\n",
        "            l=l,\n",
        "            max_delay=max_delay,\n",
        "            Q=Q,\n",
        "            rng=rng\n",
        "        )\n",
        "        company.initialize_traders(num_vars=X.shape[1], M_range=M_range)\n",
        "\n",
        "      for _ in range(max(1, int(epochs_per_update))):\n",
        "        company.train_epoch(X, y, train_t)\n",
        "\n",
        "      if len(train_t) >= int(min_fit_samples):\n",
        "        company.fit_aggregator(X, y, train_t)\n",
        "      else:\n",
        "        company.aggregator = None\n",
        "\n",
        "      last_update_step = t\n",
        "\n",
        "    pred = company.predict_one(X, t)\n",
        "    preds.append(pred)\n",
        "    actual.append(y[t + 1])\n",
        "    times.append(df.index[t])\n",
        "\n",
        "  preds = np.asarray(preds, dtype=float)\n",
        "  actual = np.asarray(actual, dtype=float)\n",
        "\n",
        "  trade_rets = company.canonical_trade_returns(preds, actual)\n",
        "  plot_equity_curve(np.array(times), trade_rets)\n",
        "\n",
        "  metrics = company.evaluate(preds, actual)\n",
        "  print(\"[Walk-forward Test]\")\n",
        "  for k, v in metrics.items():\n",
        "    print(f\"{k}:\\t{v:.3f}\")\n",
        "\n",
        "  if company.aggregator is not None:\n",
        "    plot_aggregator_coeffs(company, top_k=20, title=\"Aggregator Coefficients (Final)\")\n",
        "    describe_top_traders(company, top_k=5, var_names=df.columns.tolist())"
      ],
      "metadata": {
        "id": "UbI1jieZFRGa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "walk_forward_eval(\n",
        "    df,\n",
        "    initial_train_size=24*90,\n",
        "    retrain_every=24*7*4,\n",
        "    lookback=None,\n",
        "    epochs_per_update=1,\n",
        "    num_traders=32,\n",
        "    M_range=(1, 3),\n",
        "    Q=.5,\n",
        "    min_fit_samples=60,\n",
        "    reset_on_update=False,\n",
        ")"
      ],
      "metadata": {
        "id": "sdc80xF0Oneh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vbzDs1NAkPft"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}